1.  (User)
      |
      | uploads image (JPEG, PNG)
      v
2. Your Backend API Endpoint
      |
      | a. Receives the image file
      | b. Uploads image to Cloud Storage (S3, GCS, etc.)
      | c. Gets a public or pre-signed URL for the image
      +-------------------------------------------------+
      |                                                 |
      v                                                 v
3. Send to Multimodal LLM                           4. Send to Embedding Model
   (e.g., Gemini, GPT-4o)                              (e.g., Vertex AI, CLIP)
      |                                                 |
      | - Pass the image URL + a text prompt            | - Pass the image URL
      | - Receives a text description/analysis          | - Receives a vector embedding [0.1, 0.9, ...]
      v                                                 v
5. Your Application Logic                           6. Your Vector Database
   (e.g., show description to user)                    (e.g., save the embedding for search)