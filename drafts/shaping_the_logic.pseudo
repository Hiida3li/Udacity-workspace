1.  (User)
      |
      | uploads image (JPEG, PNG)
      v
2. Your Backend API Endpoint
      |
      | a. Receives the image file
      | b. Uploads image to Cloud Storage (S3, GCS)
      | c. Gets a public or pre-signed URL for the image
      +-------------------------------------------------+
      |                                                 |
      v                                                 v
3. Send to                                        4. Send to Embedding Model
   (Gemini)                                          (Vertex AI)
      |                                                 |
      | - Pass the image URL + a text prompt            | - Pass the image URL
      | - Receives a text description/analysis          | - Receives a vector embedding [0.1, 0.9, ...]
      v                                                 v
5. Your ApplicationLogic                           6. Your Vector Database
   ()                                                  (save embedding for search)


"""
The App starts like this when a user send an image with query the backend receives the image file.
next uploads image to Cloud Storage.
gets URL for the image
send the url to gemini to see and extract description from the image 
send the url to the search tool to make the embedding with vertex multimodal embedding 


"""




"""

gemini output to the backend to execute the tools:
Function call: { id=None args={'a': 57, 'b': 44} name='multiply' }
Function response: { id=None name='multiply' response={'result': 2508} }


"""